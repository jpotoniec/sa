{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci splotowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wprowadzenie\n",
    "### Przygotowanie danych\n",
    "Ponownie wykorzystamy w zadaniu zbiór MNIST. Zaczynamy od pobrania dnaych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "print(mnist.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każda obraz przedstawiony jest jako wektor 784 liczb, odpowiadających kolejnym pikselom. Żeby wykorzystać splotowe sieci neuronowe musimy przejść do reprezentacji trójwymiarowej: szerokosc $\\times$ wysokość $\\times$ kanały. Przekształcamy zatem macierz w czterowymiarowy tensor tak, żeby każdy obraz był trójwymiarowym tensorem $28\\times 28\\times 1$. Przy okazji dokonamy normalizacji tak, żeby wszystkie wartości były z przedziału 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = mnist.data.reshape((-1,28,28,1))\n",
    "X = X / np.max(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzielimy dane na zbiór uczący, walidujący i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, p = mnist.data.shape\n",
    "k = 10 # liczba klas\n",
    "n_train = int(.7*n)\n",
    "n_validation = int(.1*n)\n",
    "indices = np.random.permutation(n)\n",
    "train_indices = indices[:n_train]\n",
    "validation_indices = indices[n_train:n_train+n_validation]\n",
    "test_indices = indices[n_train+n_validation:]\n",
    "X_train, y_train = X[train_indices,:,:], mnist.target[train_indices]\n",
    "X_validation, y_validation = X[validation_indices,:,:], mnist.target[validation_indices]\n",
    "X_test, y_test = X[test_indices,:], mnist.target[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budowa sieci neuronowej\n",
    "\n",
    "Rozpoczynamy od przygotowania placeholderów na dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X_pl = tf.placeholder(dtype=tf.float32, shape=(None, 28, 28, 1))\n",
    "y_pl = tf.placeholder(dtype=tf.int64, shape=(None,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwsza warstwa naszej sieci będzie składała się z 6 filtrów rozmiaru $3\\times 3\\times 1$, na których uruchomiona zostanie funkcja aktywacji ELU. Zmienna `filters` będzie zawierała wagi tych filtrów. Wykorzystamy krok 1 we wszystkich wymiarach (parametr `stride`) i uzupełnianie `VALID`, tzn. przekształcone obrazy będą mniejsze o 2 piksele z każdej strony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters = tf.get_variable(name='layer1_filters', shape=(3,3,1,6))\n",
    "layer1_intermediate = tf.nn.conv2d(X_pl, filters, strides=[1,1,1,1], padding='VALID')\n",
    "layer1 = tf.nn.elu(layer1_intermediate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlmy rozmiar i sprawdźmy czy wszystko się zgadza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(layer1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nastepnie wykonamy pooling i zmniejszymy rozmiar do $12\\times 12\\times 6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer2_intermediate = tf.nn.avg_pool(layer1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "layer2 = tf.nn.elu(layer2_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(layer2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzymy warstwę wyjściową: 10 neuronów, każdy z $12\\cdot 12\\cdot 6=864$ wejściami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer3_input = tf.reshape(layer2, shape=(-1, 12*12*6))\n",
    "logits = tf.layers.dense(layer3_input, 10, activation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowujemy kolejno: \n",
    "\n",
    "* optymalizator do uczenia\n",
    "* miarę jakości\n",
    "* inicjalizator zmiennych i obiekt sesji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_pl))\n",
    "minimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.argmax(logits, axis=1)\n",
    "correct = tf.equal(y_pred, y_pl)\n",
    "correct = tf.cast(correct, dtype=tf.float32)\n",
    "acc = tf.reduce_mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizujemy zmienne, uczymy przez 1000 epok używając zbiorów po 100 przykładów, rysujemy wykres straty w czasie, obliczamy accuracy na zbiorze walidującym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)\n",
    "loss_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    indices = np.random.choice(n_train, size=100) \n",
    "    feed_dict = {X_pl: X_train[indices,...], y_pl: y_train[indices]}\n",
    "    _, loss_val = sess.run([minimizer, loss], feed_dict)\n",
    "    loss_values.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict = {X_pl: X_validation, y_pl: y_validation}\n",
    "print(sess.run(acc, feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie do samodzielnego wykonania\n",
    "\n",
    "Zaimplementuj sieć o architekturze zbliżonej do LeNet-5, zgodnie z poniższym opisem:\n",
    "\n",
    "Nr warstwy|Typ|Rozmiar wyjścia|Liczba filtrów|Rozmiar jądra (`ksize`)|Krok (`stride`)|Funkcja aktywacji|\n",
    "--- | --- | ---\n",
    "0|wejście|$32\\times 32$|obrazki trzeba najpierw uzupełnić na krawędziach zerami\n",
    "1|splotowa|$28\\times 28$|6|$5\\times 5$|1|tanh\n",
    "2|avgerage pooling|$14\\times 14$|6|$2\\times 2$|2|tanh\n",
    "3|splotowa|$10\\times 10$|16|$5\\times 5$|1|tanh\n",
    "4|average pooling|$5\\times 5$|16|$2\\times 2$|2|tanh\n",
    "5|splotowa|$1\\times 1$|120|$5\\times 5$|1|tanh\n",
    "6|pełna|84||||tanh\n",
    "7|pełna|10||||brak\n",
    "\n",
    "## Zadania szczegółowe:\n",
    "1. Uzupełnij obrazki zerami\n",
    "2. Podziel dane na trzy podzbiory\n",
    "3. Zbuduj sieć\n",
    "4. Ucz sieć wykorzystując early stopping\n",
    "5. Oceń jakość sieci na zbiorze testowym\n",
    "6. Wyświetl 10 źle zaklasyfikowanych przypadków ze zbioru testowego"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
