{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja liniowa za pomocą PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych\n",
    "\n",
    "Ponownie wykorzystamy problem przewidywania cen domów w Bostonie. Poniższy kod wczytuje dane i dzieli na trzy podzbiory: uczący, walidujący i testowy w proporcji 70%/10%/20%. Dane reprezentowane są jako obiekty typu `torch.Tensor`, tj. tensory (uogólnienie macierzy na więcej wymiarów) charakterystyczne dla biblioteki PyTorch. Parametr `dtype` wymusza konwersję na typ `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X = torch.tensor(boston['data'], dtype=torch.float)\n",
    "y = torch.tensor(boston['target'], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X.shape\n",
    "n_train = int(.7*n)\n",
    "n_validation = int(.1*n)\n",
    "indices = np.random.permutation(n)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "X_train = X[:n_train, :]\n",
    "y_train = y[:n_train]\n",
    "X_validation = X[n_train:n_train+n_validation, :]\n",
    "y_validation = y[n_train:n_train+n_validation]\n",
    "X_test = X[n_train+n_validation:, :]\n",
    "y_test = y[n_train+n_validation:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konstrukcja prostego regresora\n",
    "\n",
    "PyTorch opiera się na modułach (obiektach klasy `torch.nn.Module`), które są komponowane w graf obliczeń. Każdy z modułów może wykorzystywać parametry (obiekty klasy `torch.nn.Parameter`), dla których mogą być automatycznie liczone gradienty i które (potencjalnie) podlegają optymalizacji.\n",
    "\n",
    "Rozpoczynamy od skonstruowania pojedynczej warstwy liniowej - tj. warstwy implementującej operację $\\hat{y} = Xw + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = nn.Linear(p, 1) # p cech na wejściu, jedna cecha na wyjściu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do obliczania wartości błędu wykorzystamy błąd średniokwadratowy. PyTorch dostarcza gotowej implementacji w postaci klasy `torch.nn.MSELoss()`, natomiast ze względów dydaktycznych zaimplementujemy to samodzielnie. Kluczowe jest odziedziczenie po klasie `torch.nn.Module`, a następnie przeciążenie metody `forward`, która jest odpowiedzialna za wykonywanie obliczeń \"w przód\". Obliczenia w tył (tj. przepływ gradientów) jest realizowany automatycznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSE, self).__init__()\n",
    "        \n",
    "    def forward(self, prediction, target):\n",
    "        return ((prediction-target)**2).mean()\n",
    "\n",
    "mse = MSE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chcemy, żeby zmienne `W` oraz `b` automatycznie się zoptyamlizowały w procesie uczenia. Wykorzystamy w tym celu klasę `torch.optim.Adam`, która implementuje pewne ulepszenie algorytmu Gradient Descent. Tworzymy obiekt `opt`, który będzie odpowiedzialny za optymalizację parametrów regresora, uzyskanych przez wywołanie `regressor.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(regressor.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uruchomienie obliczeń\n",
    "\n",
    "\n",
    "Zaimplementujemy uczenie mini-batch przez `n_epoch` epok. W ramach każdej z epok:\n",
    "1. Wymieszamy indeksy zbioru treningowego\n",
    "2. Będziemy iterowali po tych indeksach, biorąc za każdym razem `batch_size` z nich. Za pomocą tych indeksów wybierzemy obiekty wykorzysytwane w danym kroku do uczenia.\n",
    "3. Zerujemy gradienty zapamiętane przez optymalizator (`opt.zero_grad()`)\n",
    "4. Uruchamiamy regresor, obliczamy błąd średniokwadratowy\n",
    "5. Obliczamy gradienty (`mse_value.backward()`)\n",
    "6. Aplikujemy gradienty (`opt.step()`)\n",
    "7. Zapamiętujemy wartość MSE. Wywołujemy metodę `detach()`, żeby zapamiętane MSE nie było powiązane ze swoimi gradientami.\n",
    "\n",
    "Po wykonaniu epoki uśredniamy zebrane MSE i zapmiętujęmy tę wartość"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values = []\n",
    "batch_size = 100\n",
    "n_epoch = 1000\n",
    "for epoch in range(n_epoch):\n",
    "    indices = np.random.permutation(n_train)\n",
    "    mse_epoch = []\n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        end = min(start + batch_size, len(indices))\n",
    "        indices_batch = indices[start:end]\n",
    "        X_batch = X_train[indices_batch, :]\n",
    "        y_batch = y_train[indices_batch]\n",
    "        opt.zero_grad()\n",
    "        y_pred = regressor(X_batch).reshape((-1,))\n",
    "        mse_value = mse(y_pred, y_batch)\n",
    "        mse_value.backward()\n",
    "        opt.step()\n",
    "        mse_epoch.append(mse_value.detach())\n",
    "    mse_values.append(np.mean(mse_epoch))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchom ponownie powyższe dwie komórki z kodem. Ponieważ regresor i optymalizator ciągle reprezentują te same obiekty, więc już nauczone wartości parametrów są pamiętane i wykres wygląda zupełnie inaczej. Żeby powrócić do stanu początkowego trzeba stworzyć na nowo obiekty `regressor` i `opt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "\n",
    "Zaimplementuj early stopping: Po każdej epoce uczenia oblicz wartość MSE za pomocą zbiorów `X_validation` i `y_validation`. Zwróć uwagę na wywołanie metod `regressor.train()` i `regressor.eval()`, które przełączają moduł między trybem uczenia, a trybem wykonywania faktycznych obliczeń. Pamiętaj, żeby nie wywoływać metody `opt.step()` po wykonaniu obliczeń na zbiorze walidującym. Przerwij uczenie jeżeli przez ostatnie 100 epok nie udało się znaleźć lepszej wartości `mse`. Zapamiętuj warotści `mse` uzyskane podczas uczenia i podczas walidacji (odpowiednio w `train_mses` i `validation_mses`), a następnie narysuj je na wykresie. Wypisz, w którym kroku zostało przerwane uczenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = nn.Linear(p, 1) # p cech na wejściu, jedna cecha na wyjściu\n",
    "opt = optim.Adam(regressor.parameters())\n",
    "\n",
    "train_mses = []\n",
    "validation_mses = []\n",
    "batch_size = 100\n",
    "n_epoch = 10000\n",
    "for epoch in range(n_epoch):\n",
    "    regressor.train()\n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        ...\n",
    "    regressor.eval()\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_mses, 'b') #błąd uczenia na niebiesko\n",
    "plt.plot(validation_mses, 'r') # błąd walidacji na czerwono\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularyzacja L1\n",
    "\n",
    "Zaimplementuj regularyzację L1 zgodnie z poniższym wzorem, implementując metodę `forward` w klasie `MSEWithL1`\n",
    "\n",
    "$$ cost = MSE + \\alpha \\sum_{i=1}^n \\left|w_i\\right| $$\n",
    "\n",
    "Wykorzystaj metody `abs()` i `sum()` obiektów klasy `torch.Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSEWithL1(nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha, weight):\n",
    "        super(MSEWithL1, self).__init__()\n",
    "        self._weight = weight\n",
    "        self._alpha = alpha\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        return ((pred-target)**2).mean() + self._alpha * self._weight.abs().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestuj uzyskane rozwiązanie: ucz przez 5000 epok dla wartości każdej z następujacych wartości $\\alpha$: 0.01, 0.1, 1, 10, 100. Za każdym razem twórz na nowo regresor i optymalizator. Zbieraj co epokę MSE (nie całkowity koszt z klasy `MSEWithL1`) na zbiorze walidującym i narysuj je na wspólnym wykresie dla wszystkich 5 wartości hiperparametru $\\alpha$. Która z wartości $\\alpha$ jest najlepsza?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE()\n",
    "\n",
    "mses = {}\n",
    "for alpha in [0.01, 0.1, 1, 10, 100]:    \n",
    "    regressor = ...\n",
    "    opt = ...\n",
    "    cost = MSEWithL1(alpha, regressor.weight)\n",
    "    mses[alpha] = [] # tu zachowuj wartości błędu na zbiorze walidującym    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in sorted(mses.keys()):\n",
    "    plt.plot(mses[alpha])\n",
    "plt.legend([str(alpha) for alpha in sorted(mses.keys())])\n",
    "plt.show()\n",
    "for alpha in sorted(mses.keys()):\n",
    "    plt.plot(mses[alpha][200:])\n",
    "plt.legend([str(alpha) for alpha in sorted(mses.keys())])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Która z wartości $\\alpha$ jest najlepsza? ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
